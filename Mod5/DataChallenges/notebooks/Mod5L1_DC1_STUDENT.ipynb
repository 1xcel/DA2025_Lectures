{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Mod5 Data Challenge 1: ETL-in-the-Wild ‚Äî Cleaning Civic Data for Product Insights\n",
    "\n",
    "### üéØ Purpose\n",
    "\n",
    "Practice applying the \"Transform\" step of an ETL pipeline using a real-world dataset‚ÄîNYC 311 Service Requests. You‚Äôll clean, standardize, and engineer features to prep the data for downstream analysis and business reporting.\n",
    "\n",
    "### üìö KSBs\n",
    "\n",
    "K14 ‚Äì Strategic feature engineering to improve analysis outcomes\n",
    "\n",
    "S5 ‚Äì Data transformation techniques in Python\n",
    "\n",
    "S8 ‚Äì Uses Pandas for EDA and data manipulation\n",
    "\n",
    "B4 ‚Äì Exercises critical judgment about data quality and reliability\n",
    "\n",
    "B6 ‚Äì Pursues deeper insights beyond surface-level observations\n",
    "\n",
    "### Data\n",
    "Use the **nyc311.csv** file located in your Github's `data` folder within Mod5/DataChallenges.  This is a sample of the originial file looking at just one week of data since the dataset is HUGE.  Read more about the columns [HERE](https://data.cityofnewyork.us/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9/about_data).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üë©‚Äçüè´ Instructor-Led Demo (15 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1:  Load + Preview \n",
    "* Read in data\n",
    "\n",
    "* Show .head(), .info() to examine structure and datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55815 entries, 0 to 55814\n",
      "Data columns (total 41 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Unique Key                      55815 non-null  int64  \n",
      " 1   Created Date                    55815 non-null  object \n",
      " 2   Closed Date                     41348 non-null  object \n",
      " 3   Agency                          55815 non-null  object \n",
      " 4   Agency Name                     55815 non-null  object \n",
      " 5   Complaint Type                  55815 non-null  object \n",
      " 6   Descriptor                      54400 non-null  object \n",
      " 7   Location Type                   49701 non-null  object \n",
      " 8   Incident Zip                    55361 non-null  float64\n",
      " 9   Incident Address                54235 non-null  object \n",
      " 10  Street Name                     54233 non-null  object \n",
      " 11  Cross Street 1                  46608 non-null  object \n",
      " 12  Cross Street 2                  46637 non-null  object \n",
      " 13  Intersection Street 1           44052 non-null  object \n",
      " 14  Intersection Street 2           44091 non-null  object \n",
      " 15  Address Type                    55621 non-null  object \n",
      " 16  City                            52708 non-null  object \n",
      " 17  Landmark                        40086 non-null  object \n",
      " 18  Facility Type                   134 non-null    object \n",
      " 19  Status                          55815 non-null  object \n",
      " 20  Due Date                        328 non-null    object \n",
      " 21  Resolution Description          48016 non-null  object \n",
      " 22  Resolution Action Updated Date  48870 non-null  object \n",
      " 23  Community Board                 55815 non-null  object \n",
      " 24  BBL                             49122 non-null  float64\n",
      " 25  Borough                         55815 non-null  object \n",
      " 26  X Coordinate (State Plane)      54942 non-null  float64\n",
      " 27  Y Coordinate (State Plane)      54943 non-null  float64\n",
      " 28  Open Data Channel Type          55815 non-null  object \n",
      " 29  Park Facility Name              55675 non-null  object \n",
      " 30  Park Borough                    55815 non-null  object \n",
      " 31  Vehicle Type                    2871 non-null   object \n",
      " 32  Taxi Company Borough            31 non-null     object \n",
      " 33  Taxi Pick Up Location           494 non-null    object \n",
      " 34  Bridge Highway Name             277 non-null    object \n",
      " 35  Bridge Highway Direction        139 non-null    object \n",
      " 36  Road Ramp                       118 non-null    object \n",
      " 37  Bridge Highway Segment          277 non-null    object \n",
      " 38  Latitude                        54942 non-null  float64\n",
      " 39  Longitude                       54942 non-null  float64\n",
      " 40  Location                        54942 non-null  object \n",
      "dtypes: float64(6), int64(1), object(34)\n",
      "memory usage: 17.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/Marcy_Student/DA2025_Lectures/DA2025_Lectures/Mod5/DataChallenges/data/nyc311.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2:  Clean up Categorical Variable \n",
    "\n",
    "* Normalize Borough & Complaint Type (e.g., strip whitespace, title-case or upper-case values)\n",
    "\n",
    "* Show .value_counts() before and after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Complaint Type\n",
       "None    41348\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Borough\n",
       "None    41348\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Strip whitespace and standardize case\n",
    "for col in [\"Complaint Type\", \"Borough\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "# pick a style (title-case often reads nicely)\n",
    "df[\"Complaint Type\"] = df['Complaint Type'].str.title()\n",
    "df[\"Borough\"] = df['Borough'].str.title()\n",
    "\n",
    "# quick sanity checks\n",
    "display(df[\"Complaint Type\"].value_counts().head(10))\n",
    "display(df[\"Borough\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3:  Feature Engineering\n",
    "\n",
    "* Convert Created Date to datetime\n",
    "\n",
    "* Create a new feature: is_weekend based on weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Created Date\"] =pd.to_datetime(df['Created Date'])\n",
    "\n",
    "# is_weekend flag\n",
    "\n",
    "df[\"is_weekend\"] = df['Created Date'].dt.day_of_week > 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üë©‚Äçüíª Student-Led Section (30 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task1:  Clean & Filter\n",
    "\n",
    "* Drop rows with missing Created Date or Closed Date\n",
    "\n",
    "* Drop duplicate rows\n",
    "\n",
    "* Filter data to only include one borough (e.g., Brooklyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 42)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1a) Drop rows with missing Created/Closed Date\n",
    "df = df.dropna (subset=['Created Date','Closed Date'])\n",
    "\n",
    "# 1b) Drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# 1c) Filter to a single borough (STUDENT CHOICE)\n",
    "borough_name = 'Brooklyn' # e.g., \"Brooklyn\"\n",
    "df_b = df[df[\"Borough\"] == borough_name].copy()\n",
    "df_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unique Key                            0\n",
       "Created Date                          0\n",
       "Closed Date                           0\n",
       "Agency                                0\n",
       "Agency Name                           0\n",
       "Complaint Type                        0\n",
       "Descriptor                         1264\n",
       "Location Type                      3507\n",
       "Incident Zip                        316\n",
       "Incident Address                   1017\n",
       "Street Name                        1018\n",
       "Cross Street 1                     3474\n",
       "Cross Street 2                     3438\n",
       "Intersection Street 1              4481\n",
       "Intersection Street 2              4441\n",
       "Address Type                        142\n",
       "City                               2423\n",
       "Landmark                           7430\n",
       "Facility Type                     41218\n",
       "Status                                0\n",
       "Due Date                          41340\n",
       "Resolution Description              646\n",
       "Resolution Action Updated Date        0\n",
       "Community Board                       0\n",
       "BBL                                5016\n",
       "Borough                               0\n",
       "X Coordinate (State Plane)          555\n",
       "Y Coordinate (State Plane)          555\n",
       "Open Data Channel Type                0\n",
       "Park Facility Name                  132\n",
       "Park Borough                          0\n",
       "Vehicle Type                      38532\n",
       "Taxi Company Borough              41348\n",
       "Taxi Pick Up Location             41294\n",
       "Bridge Highway Name               41162\n",
       "Bridge Highway Direction          41265\n",
       "Road Ramp                         41274\n",
       "Bridge Highway Segment            41162\n",
       "Latitude                            555\n",
       "Longitude                           555\n",
       "Location                            555\n",
       "is_weekend                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task2:  Time Transformations \n",
    "\n",
    "* Create a new column `response_time_hrs` = difference between Closed Date and Created Date (in hours)\n",
    "\n",
    "* Ensure datetime types are properly parsed and timezone-aware (localize to America/New_York ‚Üí convert to UTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL WITHOUT CHANGES!!!! \n",
    "\n",
    "LOCAL_TZ = \"America/New_York\"\n",
    "\n",
    "def to_utc(series, local_tz=LOCAL_TZ):\n",
    "    # 1) parse\n",
    "    s = pd.to_datetime(series, errors=\"coerce\")\n",
    "\n",
    "    # 2) if naive -> localize; if tz-aware -> skip (KEEP NONE in this if statement)\n",
    "    if s.dt.tz is None:\n",
    "        s = s.dt.tz_localize(local_tz, nonexistent=\"shift_forward\", ambiguous=\"NaT\")\n",
    "\n",
    "    # 3) convert whatever tz it has to UTC\n",
    "    return s.dt.tz_convert(\"UTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert both columns to utc\n",
    "df_b[\"Created Date\"] = to_utc(df_b[\"Created Date\"])\n",
    "df_b[\"Closed Date\"]  = to_utc(df_b['Closed Date'])\n",
    "\n",
    "# Now compute the response time\n",
    "delta = df_b[\"Closed Date\"] - df_b[\"Created Date\"]\n",
    "df_b[\"response_time_hrs\"] = delta.dt.total_seconds() / 3600\n",
    "\n",
    "# Check the data with a .head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task3:  Feature Engineer\n",
    "\n",
    "* Create `hour_of_day` from Created Date\n",
    "\n",
    "* Create `is_high_priority`: True if Complaint Type is in a list of priority complaints (e.g., [\"HEAT/HOT WATER\", \"ELECTRIC\", \"STRUCTURAL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Complaint Type</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>is_high_priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Complaint Type  hour_of_day  is_high_priority\n",
       "7             NaN            1             False\n",
       "37            NaN            1             False\n",
       "43            NaN            1             False\n",
       "47            NaN            1             False\n",
       "50            NaN            1             False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7        None\n",
      "37       None\n",
      "43       None\n",
      "47       None\n",
      "50       None\n",
      "         ... \n",
      "55810    None\n",
      "55811    None\n",
      "55812    None\n",
      "55813    None\n",
      "55814    None\n",
      "Name: Complaint Type, Length: 41348, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# hour_of_day from Created Date \n",
    "df_b[\"hour_of_day\"] = df['Created Date'].dt.hour\n",
    "\n",
    "# define a high-priority list (STUDENT CHOICE)\n",
    "priority_list = ['Electric','Structural' ] # e.g., [\"Heat/Hot Water\",\"Electric\",\"Elevator\",\"Structural\"\n",
    "df_b[\"is_high_priority\"] = df_b['Complaint Type'].isin(priority_list)\n",
    "\n",
    "display(df_b[[\"Complaint Type\",\"hour_of_day\",\"is_high_priority\"]].head(5))\n",
    "print ( df['Complaint Type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task4:  Aggregates & Visuals \n",
    "\n",
    "* Average response time by Complaint Type (sorted descending)\n",
    "\n",
    "* Total number of complaints by hour_of_day (bar chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average response time by complaint type (descending)\n",
    "avg_resp = (df_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total complaints by hour_of_day (bar chart)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook Reflection\n",
    "\n",
    "Answer the questions in a markdown cell below.  Be thorough (no need to use AWES just answer the question fully)\n",
    "\n",
    "1. Describe one transformation or feature you engineered (e.g., response_time_hrs, is_high_priority) and explain why it would be useful for a city analyst or operations manager.\n",
    "\n",
    "2. What could go wrong if you didn‚Äôt clean the datetime fields properly or skipped removing rows with missing Closed Date? How might that distort future dashboards or decisions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üì£ Class Share-Out (15 minutes)\n",
    "\n",
    "Be ready to share out the following points with the class: \n",
    "\n",
    "üì£ Explain:\n",
    "\n",
    "How average response_time_hrs by complaint type offers insight (e.g., ‚ÄúElevator complaints take longer to resolve‚Äù)\n",
    "\n",
    "What does your chosen borough trends reveal (e.g., ‚ÄúMost heating complaints come in before 10am‚Äù)\n",
    "\n",
    "üõ†Ô∏è Propose:\n",
    "\n",
    "One next transformation step you would include in the full data pipeline (e.g., flagging overdue requests)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
